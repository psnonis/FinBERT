00:00:02 WARNING: Logging before flag parsing goes to stderr.
00:00:02 W0803 00:22:43.566170 140129369089856 deprecation_wrapper.py:119] From /root/w266-final/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.
00:00:02 
00:00:02 W0803 00:22:43.567372 140129369089856 deprecation_wrapper.py:119] From /root/w266-final/bert/run_pretraining.py:493: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.
00:00:02 
00:00:02 W0803 00:22:43.568013 140129369089856 deprecation_wrapper.py:119] From /root/w266-final/bert/run_pretraining.py:407: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
00:00:02 
00:00:02 W0803 00:22:43.568187 140129369089856 deprecation_wrapper.py:119] From /root/w266-final/bert/run_pretraining.py:407: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
00:00:02 
00:00:02 W0803 00:22:43.568371 140129369089856 deprecation_wrapper.py:119] From /root/w266-final/bert/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.
00:00:02 
00:00:02 W0803 00:22:43.569106 140129369089856 deprecation_wrapper.py:119] From /root/w266-final/bert/run_pretraining.py:414: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.
00:00:02 
00:00:02 W0803 00:22:43.569323 140129369089856 deprecation_wrapper.py:119] From /root/w266-final/bert/run_pretraining.py:418: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.
00:00:02 
00:00:02 W0803 00:22:43.570940 140129369089856 deprecation_wrapper.py:119] From /root/w266-final/bert/run_pretraining.py:420: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
00:00:02 
00:00:02 I0803 00:22:43.571072 140129369089856 run_pretraining.py:420] *** Input Files ***
00:00:02 I0803 00:22:43.571179 140129369089856 run_pretraining.py:422]   /root/w266-final/eval/2019/2019.tfrecord.05-128-20
00:00:02 I0803 00:22:43.571275 140129369089856 run_pretraining.py:422]   /root/w266-final/eval/2019/2019.tfrecord.06-128-20
00:00:02 I0803 00:22:43.571365 140129369089856 run_pretraining.py:422]   /root/w266-final/eval/2019/2019.tfrecord.04-128-20
00:00:02 I0803 00:22:43.571453 140129369089856 run_pretraining.py:422]   /root/w266-final/eval/2019/2019.tfrecord.01-128-20
00:00:02 I0803 00:22:43.571538 140129369089856 run_pretraining.py:422]   /root/w266-final/eval/2019/2019.tfrecord.00-128-20
00:00:02 I0803 00:22:43.571622 140129369089856 run_pretraining.py:422]   /root/w266-final/eval/2019/2019.tfrecord.07-128-20
00:00:02 I0803 00:22:43.571706 140129369089856 run_pretraining.py:422]   /root/w266-final/eval/2019/2019.tfrecord.03-128-20
00:00:02 I0803 00:22:43.571791 140129369089856 run_pretraining.py:422]   /root/w266-final/eval/2019/2019.tfrecord.02-128-20
00:00:03 W0803 00:22:44.134510 140129369089856 lazy_loader.py:50] 
00:00:03 The TensorFlow contrib module will not be included in TensorFlow 2.0.
00:00:03 For more information, please see:
00:00:03   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
00:00:03   * https://github.com/tensorflow/addons
00:00:03   * https://github.com/tensorflow/io (for I/O related ops)
00:00:03 If you depend on functionality not listed there, please file an issue.
00:00:03 
00:00:03 W0803 00:22:44.135223 140129369089856 estimator.py:1984] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f72346e7e18>) includes params argument, but params are not passed to Estimator.
00:00:03 I0803 00:22:44.136538 140129369089856 estimator.py:209] Using config: {'_model_dir': '/root/w266-final/eval/ckpt/FinBERT-Prime_128MSL-500K_512MSL-200K', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true
00:00:03 graph_options {
00:00:03   rewrite_options {
00:00:03     meta_optimizer_iterations: ONE
00:00:03   }
00:00:03 }
00:00:03 , '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f725c3786d8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2), '_cluster': None}
00:00:03 I0803 00:22:44.137224 140129369089856 tpu_context.py:209] _TPUContext: eval_on_tpu True
00:00:03 W0803 00:22:44.137747 140129369089856 tpu_context.py:211] eval_on_tpu ignored because use_tpu is False.
00:00:03 I0803 00:22:44.137884 140129369089856 run_pretraining.py:469] ***** Running evaluation *****
00:00:03 I0803 00:22:44.137999 140129369089856 run_pretraining.py:470]   Batch size = 8
00:00:03 W0803 00:22:44.188206 140129369089856 deprecation_wrapper.py:119] From /root/w266-final/bert/run_pretraining.py:337: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.
00:00:03 
00:00:03 W0803 00:22:44.215571 140129369089856 deprecation.py:323] From /root/w266-final/bert/run_pretraining.py:385: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.
00:00:03 Instructions for updating:
00:00:03 Use `tf.data.experimental.map_and_batch(...)`.
00:00:03 W0803 00:22:44.215747 140129369089856 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/data/python/ops/batching.py:273: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.
00:00:03 Instructions for updating:
00:00:03 Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.
00:00:03 W0803 00:22:44.217511 140129369089856 deprecation_wrapper.py:119] From /root/w266-final/bert/run_pretraining.py:393: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.
00:00:03 
00:00:03 W0803 00:22:44.224845 140129369089856 deprecation.py:323] From /root/w266-final/bert/run_pretraining.py:400: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
00:00:03 Instructions for updating:
00:00:03 Use `tf.cast` instead.
00:00:03 I0803 00:22:44.256131 140129369089856 estimator.py:1145] Calling model_fn.
00:00:03 I0803 00:22:44.256373 140129369089856 tpu_estimator.py:2965] Running eval on CPU
00:00:03 I0803 00:22:44.256837 140129369089856 run_pretraining.py:117] *** Features ***
00:00:03 I0803 00:22:44.257023 140129369089856 run_pretraining.py:119]   name = input_ids, shape = (8, 128)
00:00:03 I0803 00:22:44.257177 140129369089856 run_pretraining.py:119]   name = input_mask, shape = (8, 128)
00:00:03 I0803 00:22:44.257319 140129369089856 run_pretraining.py:119]   name = masked_lm_ids, shape = (8, 20)
00:00:03 I0803 00:22:44.257457 140129369089856 run_pretraining.py:119]   name = masked_lm_positions, shape = (8, 20)
00:00:03 I0803 00:22:44.257590 140129369089856 run_pretraining.py:119]   name = masked_lm_weights, shape = (8, 20)
00:00:03 I0803 00:22:44.257722 140129369089856 run_pretraining.py:119]   name = next_sentence_labels, shape = (8, 1)
00:00:03 I0803 00:22:44.257858 140129369089856 run_pretraining.py:119]   name = segment_ids, shape = (8, 128)
00:00:03 W0803 00:22:44.258115 140129369089856 deprecation_wrapper.py:119] From /root/w266-final/bert/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.
00:00:03 
00:00:03 W0803 00:22:44.260288 140129369089856 deprecation_wrapper.py:119] From /root/w266-final/bert/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.
00:00:03 
00:00:03 W0803 00:22:44.293133 140129369089856 deprecation_wrapper.py:119] From /root/w266-final/bert/modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.
00:00:03 
00:00:03 W0803 00:22:44.346298 140129369089856 deprecation.py:323] From /root/w266-final/bert/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
00:00:03 Instructions for updating:
00:00:03 Use keras.layers.dense instead.
00:00:06 I0803 00:22:47.502273 140129369089856 run_pretraining.py:167] **** Trainable Variables ****
00:00:06 I0803 00:22:47.502538 140129369089856 run_pretraining.py:173]   name = bert/embeddings/word_embeddings:0, shape = (30522, 768)
00:00:06 I0803 00:22:47.502743 140129369089856 run_pretraining.py:173]   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768)
00:00:06 I0803 00:22:47.502902 140129369089856 run_pretraining.py:173]   name = bert/embeddings/position_embeddings:0, shape = (512, 768)
00:00:06 I0803 00:22:47.503048 140129369089856 run_pretraining.py:173]   name = bert/embeddings/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 00:22:47.503186 140129369089856 run_pretraining.py:173]   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 00:22:47.503324 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768)
00:00:06 I0803 00:22:47.503463 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.503583 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768)
00:00:06 I0803 00:22:47.503727 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.503862 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768)
00:00:06 I0803 00:22:47.503996 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.504137 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 00:22:47.504281 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.504412 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 00:22:47.504540 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 00:22:47.504670 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072)
00:00:06 I0803 00:22:47.504805 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,)
00:00:06 I0803 00:22:47.504938 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768)
00:00:06 I0803 00:22:47.505071 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.505199 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 00:22:47.505326 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 00:22:47.505455 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768)
00:00:06 I0803 00:22:47.505586 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.505716 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768)
00:00:06 I0803 00:22:47.505849 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.505978 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768)
00:00:06 I0803 00:22:47.506115 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.506247 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 00:22:47.506378 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.506505 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 00:22:47.506659 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 00:22:47.506794 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072)
00:00:06 I0803 00:22:47.506927 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,)
00:00:06 I0803 00:22:47.507058 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768)
00:00:06 I0803 00:22:47.507192 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.507319 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 00:22:47.507460 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 00:22:47.507589 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768)
00:00:06 I0803 00:22:47.507727 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.507860 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768)
00:00:06 I0803 00:22:47.507993 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.508122 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768)
00:00:06 I0803 00:22:47.508253 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.508384 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 00:22:47.508517 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.508644 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 00:22:47.508771 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 00:22:47.508901 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072)
00:00:06 I0803 00:22:47.509040 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,)
00:00:06 I0803 00:22:47.509172 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768)
00:00:06 I0803 00:22:47.509305 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.509433 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 00:22:47.509559 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 00:22:47.509689 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768)
00:00:06 I0803 00:22:47.509821 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.509952 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768)
00:00:06 I0803 00:22:47.510085 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.510215 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768)
00:00:06 I0803 00:22:47.510348 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.510483 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 00:22:47.510642 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.510783 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 00:22:47.510913 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 00:22:47.511044 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072)
00:00:06 I0803 00:22:47.511175 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,)
00:00:06 I0803 00:22:47.511305 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768)
00:00:06 I0803 00:22:47.511438 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.511567 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 00:22:47.511693 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 00:22:47.511837 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768)
00:00:06 I0803 00:22:47.511970 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.512101 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768)
00:00:06 I0803 00:22:47.512233 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.512364 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768)
00:00:06 I0803 00:22:47.512495 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.512629 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 00:22:47.512760 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.512887 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 00:22:47.513015 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 00:22:47.513144 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072)
00:00:06 I0803 00:22:47.513276 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,)
00:00:06 I0803 00:22:47.513408 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768)
00:00:06 I0803 00:22:47.513541 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.513676 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 00:22:47.513803 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 00:22:47.513935 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768)
00:00:06 I0803 00:22:47.514069 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.514209 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768)
00:00:06 I0803 00:22:47.514342 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.514473 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768)
00:00:06 I0803 00:22:47.514629 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.514770 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 00:22:47.514902 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.515031 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 00:22:47.515156 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 00:22:47.515286 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072)
00:00:06 I0803 00:22:47.515418 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,)
00:00:06 I0803 00:22:47.515549 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768)
00:00:06 I0803 00:22:47.515680 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.515817 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 00:22:47.515954 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 00:22:47.516087 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768)
00:00:06 I0803 00:22:47.516225 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.516358 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768)
00:00:06 I0803 00:22:47.516491 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.516622 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768)
00:00:06 I0803 00:22:47.516818 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.516960 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 00:22:47.517094 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.517222 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 00:22:47.517348 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 00:22:47.517484 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072)
00:00:06 I0803 00:22:47.517617 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,)
00:00:06 I0803 00:22:47.517748 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768)
00:00:06 I0803 00:22:47.517880 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.518008 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 00:22:47.518136 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 00:22:47.518267 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768)
00:00:06 I0803 00:22:47.518400 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.518530 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768)
00:00:06 I0803 00:22:47.518688 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.518823 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768)
00:00:06 I0803 00:22:47.518956 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.519087 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 00:22:47.519220 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.519350 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 00:22:47.519478 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 00:22:47.519606 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072)
00:00:06 I0803 00:22:47.519737 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,)
00:00:06 I0803 00:22:47.519869 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768)
00:00:06 I0803 00:22:47.520013 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.520142 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 00:22:47.520270 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 00:22:47.520399 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768)
00:00:06 I0803 00:22:47.520531 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.520660 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768)
00:00:06 I0803 00:22:47.520794 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.520924 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768)
00:00:06 I0803 00:22:47.521055 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.521184 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 00:22:47.521316 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.521443 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 00:22:47.521569 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 00:22:47.521697 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072)
00:00:06 I0803 00:22:47.521827 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,)
00:00:06 I0803 00:22:47.521957 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768)
00:00:06 I0803 00:22:47.522089 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.522216 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 00:22:47.522342 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 00:22:47.522471 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768)
00:00:06 I0803 00:22:47.522604 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.522769 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768)
00:00:06 I0803 00:22:47.522902 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.523033 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768)
00:00:06 I0803 00:22:47.523218 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.523401 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 00:22:47.523541 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.523670 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 00:22:47.523796 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 00:22:47.523925 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072)
00:00:06 I0803 00:22:47.524067 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,)
00:00:06 I0803 00:22:47.524210 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768)
00:00:06 I0803 00:22:47.524347 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.524475 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 00:22:47.524603 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 00:22:47.524733 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768)
00:00:06 I0803 00:22:47.524864 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.524993 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768)
00:00:06 I0803 00:22:47.525123 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.525253 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768)
00:00:06 I0803 00:22:47.525385 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.525513 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 00:22:47.525643 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.525769 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 00:22:47.525896 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 00:22:47.526023 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072)
00:00:06 I0803 00:22:47.526154 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,)
00:00:06 I0803 00:22:47.526287 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768)
00:00:06 I0803 00:22:47.526419 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.526544 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 00:22:47.526709 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 00:22:47.526842 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768)
00:00:06 I0803 00:22:47.526973 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.527101 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768)
00:00:06 I0803 00:22:47.527231 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.527359 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768)
00:00:06 I0803 00:22:47.527490 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.527619 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 00:22:47.527750 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.527877 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 00:22:47.528011 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 00:22:47.528143 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072)
00:00:06 I0803 00:22:47.528275 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,)
00:00:06 I0803 00:22:47.528402 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768)
00:00:06 I0803 00:22:47.528532 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.528658 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 00:22:47.528783 140129369089856 run_pretraining.py:173]   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 00:22:47.528916 140129369089856 run_pretraining.py:173]   name = bert/pooler/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 00:22:47.529047 140129369089856 run_pretraining.py:173]   name = bert/pooler/dense/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.529176 140129369089856 run_pretraining.py:173]   name = cls/predictions/transform/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 00:22:47.529307 140129369089856 run_pretraining.py:173]   name = cls/predictions/transform/dense/bias:0, shape = (768,)
00:00:06 I0803 00:22:47.529440 140129369089856 run_pretraining.py:173]   name = cls/predictions/transform/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 00:22:47.529567 140129369089856 run_pretraining.py:173]   name = cls/predictions/transform/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 00:22:47.529692 140129369089856 run_pretraining.py:173]   name = cls/predictions/output_bias:0, shape = (30522,)
00:00:06 I0803 00:22:47.529820 140129369089856 run_pretraining.py:173]   name = cls/seq_relationship/output_weights:0, shape = (2, 768)
00:00:06 I0803 00:22:47.529950 140129369089856 run_pretraining.py:173]   name = cls/seq_relationship/output_bias:0, shape = (2,)
00:00:06 W0803 00:22:47.538560 140129369089856 deprecation_wrapper.py:119] From /root/w266-final/bert/run_pretraining.py:198: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.
00:00:06 
00:00:06 W0803 00:22:47.561433 140129369089856 deprecation_wrapper.py:119] From /root/w266-final/bert/run_pretraining.py:202: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.
00:00:06 
00:00:06 I0803 00:22:47.626677 140129369089856 estimator.py:1147] Done calling model_fn.
00:00:06 I0803 00:22:47.654329 140129369089856 evaluation.py:255] Starting evaluation at 2019-08-03T00:22:47Z
00:00:06 W0803 00:22:47.891130 140129369089856 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
00:00:06 Instructions for updating:
00:00:06 Use tf.where in 2.0, which has the same broadcast rule as np.where
00:00:07 I0803 00:22:48.387711 140129369089856 monitored_session.py:240] Graph was finalized.
00:00:07 2019-08-03 00:22:48.388161: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
00:00:07 2019-08-03 00:22:48.397592: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000024999 Hz
00:00:07 2019-08-03 00:22:48.398488: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56cd9b0 executing computations on platform Host. Devices:
00:00:07 2019-08-03 00:22:48.398526: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
00:00:07 W0803 00:22:48.399517 140129369089856 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
00:00:07 Instructions for updating:
00:00:07 Use standard file APIs to check for files with this prefix.
00:00:07 I0803 00:22:48.400869 140129369089856 saver.py:1280] Restoring parameters from /root/w266-final/eval/ckpt/FinBERT-Prime_128MSL-500K_512MSL-200K/model.ckpt-700000
00:00:07 2019-08-03 00:22:48.710991: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
00:00:15 I0803 00:22:56.219652 140129369089856 session_manager.py:500] Running local_init_op.
00:00:15 I0803 00:22:56.270548 140129369089856 session_manager.py:502] Done running local_init_op.
00:00:23 I0803 00:23:04.991304 140129369089856 evaluation.py:167] Evaluation [10/100]
00:00:31 I0803 00:23:12.915987 140129369089856 evaluation.py:167] Evaluation [20/100]
00:00:39 I0803 00:23:20.837538 140129369089856 evaluation.py:167] Evaluation [30/100]
00:00:47 I0803 00:23:28.665510 140129369089856 evaluation.py:167] Evaluation [40/100]
00:00:55 I0803 00:23:36.464632 140129369089856 evaluation.py:167] Evaluation [50/100]
00:01:03 I0803 00:23:44.378288 140129369089856 evaluation.py:167] Evaluation [60/100]
00:01:11 I0803 00:23:52.298085 140129369089856 evaluation.py:167] Evaluation [70/100]
00:01:19 I0803 00:24:00.259600 140129369089856 evaluation.py:167] Evaluation [80/100]
00:01:27 I0803 00:24:08.170251 140129369089856 evaluation.py:167] Evaluation [90/100]
00:01:35 I0803 00:24:16.099749 140129369089856 evaluation.py:167] Evaluation [100/100]
00:01:35 I0803 00:24:16.200621 140129369089856 evaluation.py:275] Finished evaluation at 2019-08-03-00:24:16
00:01:35 I0803 00:24:16.201034 140129369089856 estimator.py:2039] Saving dict for global step 700000: global_step = 700000, loss = 1.4487245, masked_lm_accuracy = 0.7345848, masked_lm_loss = 1.2200583, next_sentence_accuracy = 0.92875, next_sentence_loss = 0.23120661
00:01:35 I0803 00:24:16.773230 140129369089856 estimator.py:2099] Saving 'checkpoint_path' summary for global step 700000: /root/w266-final/eval/ckpt/FinBERT-Prime_128MSL-500K_512MSL-200K/model.ckpt-700000
00:01:35 I0803 00:24:16.774017 140129369089856 error_handling.py:96] evaluation_loop marked as finished
00:01:35 I0803 00:24:16.774281 140129369089856 run_pretraining.py:483] ***** Eval results *****
00:01:35 I0803 00:24:16.774453 140129369089856 run_pretraining.py:485]   global_step = 700000
00:01:35 I0803 00:24:16.774750 140129369089856 run_pretraining.py:485]   loss = 1.4487245
00:01:35 I0803 00:24:16.774924 140129369089856 run_pretraining.py:485]   masked_lm_accuracy = 0.7345848
00:01:35 I0803 00:24:16.775081 140129369089856 run_pretraining.py:485]   masked_lm_loss = 1.2200583
00:01:35 I0803 00:24:16.775233 140129369089856 run_pretraining.py:485]   next_sentence_accuracy = 0.92875
00:01:35 I0803 00:24:16.775392 140129369089856 run_pretraining.py:485]   next_sentence_loss = 0.23120661
