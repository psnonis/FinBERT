00:00:02 WARNING: Logging before flag parsing goes to stderr.
00:00:02 W0803 19:49:38.479592 140526454683456 deprecation_wrapper.py:119] From /root/w266-final/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.
00:00:02 
00:00:02 W0803 19:49:38.479942 140526454683456 deprecation_wrapper.py:119] From /root/w266-final/bert/run_pretraining.py:26: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.
00:00:02 
00:00:02 W0803 19:49:38.480871 140526454683456 deprecation_wrapper.py:119] From /root/w266-final/bert/run_pretraining.py:495: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.
00:00:02 
00:00:02 W0803 19:49:38.481483 140526454683456 deprecation_wrapper.py:119] From /root/w266-final/bert/run_pretraining.py:409: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
00:00:02 
00:00:02 W0803 19:49:38.481656 140526454683456 deprecation_wrapper.py:119] From /root/w266-final/bert/run_pretraining.py:409: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
00:00:02 
00:00:02 W0803 19:49:38.481840 140526454683456 deprecation_wrapper.py:119] From /root/w266-final/bert/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.
00:00:02 
00:00:02 W0803 19:49:38.482574 140526454683456 deprecation_wrapper.py:119] From /root/w266-final/bert/run_pretraining.py:416: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.
00:00:02 
00:00:02 W0803 19:49:38.482835 140526454683456 deprecation_wrapper.py:119] From /root/w266-final/bert/run_pretraining.py:420: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.
00:00:02 
00:00:02 W0803 19:49:38.562397 140526454683456 deprecation_wrapper.py:119] From /root/w266-final/bert/run_pretraining.py:422: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
00:00:02 
00:00:02 I0803 19:49:38.562631 140526454683456 run_pretraining.py:422] *** Input Files ***
00:00:02 I0803 19:49:38.562735 140526454683456 run_pretraining.py:424]   /root/w266-final/eval/10-q/data/2018.tfrecord.sm-128-20
00:00:03 W0803 19:49:39.102876 140526454683456 lazy_loader.py:50] 
00:00:03 The TensorFlow contrib module will not be included in TensorFlow 2.0.
00:00:03 For more information, please see:
00:00:03   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
00:00:03   * https://github.com/tensorflow/addons
00:00:03   * https://github.com/tensorflow/io (for I/O related ops)
00:00:03 If you depend on functionality not listed there, please file an issue.
00:00:03 
00:00:03 W0803 19:49:39.103571 140526454683456 estimator.py:1984] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fcea893fe18>) includes params argument, but params are not passed to Estimator.
00:00:03 I0803 19:49:39.104914 140526454683456 estimator.py:209] Using config: {'_model_dir': '/root/w266-final/eval/10-q/ckpt/FinBERT-Combo_128MSL-100K', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true
00:00:03 graph_options {
00:00:03   rewrite_options {
00:00:03     meta_optimizer_iterations: ONE
00:00:03   }
00:00:03 }
00:00:03 , '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fcea3139fd0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2), '_cluster': None}
00:00:03 I0803 19:49:39.105616 140526454683456 tpu_context.py:209] _TPUContext: eval_on_tpu True
00:00:03 W0803 19:49:39.106126 140526454683456 tpu_context.py:211] eval_on_tpu ignored because use_tpu is False.
00:00:03 I0803 19:49:39.106321 140526454683456 run_pretraining.py:471] ***** Running evaluation *****
00:00:03 I0803 19:49:39.106434 140526454683456 run_pretraining.py:472]   Batch size = 8
00:00:03 W0803 19:49:39.151151 140526454683456 deprecation_wrapper.py:119] From /root/w266-final/bert/run_pretraining.py:339: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.
00:00:03 
00:00:03 W0803 19:49:39.177706 140526454683456 deprecation.py:323] From /root/w266-final/bert/run_pretraining.py:387: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.
00:00:03 Instructions for updating:
00:00:03 Use `tf.data.experimental.map_and_batch(...)`.
00:00:03 W0803 19:49:39.177880 140526454683456 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/data/python/ops/batching.py:273: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.
00:00:03 Instructions for updating:
00:00:03 Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.
00:00:03 W0803 19:49:39.179645 140526454683456 deprecation_wrapper.py:119] From /root/w266-final/bert/run_pretraining.py:395: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.
00:00:03 
00:00:03 W0803 19:49:39.186809 140526454683456 deprecation.py:323] From /root/w266-final/bert/run_pretraining.py:402: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
00:00:03 Instructions for updating:
00:00:03 Use `tf.cast` instead.
00:00:03 I0803 19:49:39.217091 140526454683456 estimator.py:1145] Calling model_fn.
00:00:03 I0803 19:49:39.217317 140526454683456 tpu_estimator.py:2965] Running eval on CPU
00:00:03 I0803 19:49:39.217804 140526454683456 run_pretraining.py:119] *** Features ***
00:00:03 I0803 19:49:39.217985 140526454683456 run_pretraining.py:121]   name = input_ids, shape = (8, 128)
00:00:03 I0803 19:49:39.218198 140526454683456 run_pretraining.py:121]   name = input_mask, shape = (8, 128)
00:00:03 I0803 19:49:39.218345 140526454683456 run_pretraining.py:121]   name = masked_lm_ids, shape = (8, 20)
00:00:03 I0803 19:49:39.218538 140526454683456 run_pretraining.py:121]   name = masked_lm_positions, shape = (8, 20)
00:00:03 I0803 19:49:39.218731 140526454683456 run_pretraining.py:121]   name = masked_lm_weights, shape = (8, 20)
00:00:03 I0803 19:49:39.218877 140526454683456 run_pretraining.py:121]   name = next_sentence_labels, shape = (8, 1)
00:00:03 I0803 19:49:39.219052 140526454683456 run_pretraining.py:121]   name = segment_ids, shape = (8, 128)
00:00:03 W0803 19:49:39.219323 140526454683456 deprecation_wrapper.py:119] From /root/w266-final/bert/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.
00:00:03 
00:00:03 W0803 19:49:39.221430 140526454683456 deprecation_wrapper.py:119] From /root/w266-final/bert/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.
00:00:03 
00:00:03 W0803 19:49:39.304439 140526454683456 deprecation.py:323] From /root/w266-final/bert/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
00:00:03 Instructions for updating:
00:00:03 Use keras.layers.dense instead.
00:00:06 I0803 19:49:42.377588 140526454683456 run_pretraining.py:169] **** Trainable Variables ****
00:00:06 I0803 19:49:42.377843 140526454683456 run_pretraining.py:175]   name = bert/embeddings/word_embeddings:0, shape = (30522, 768)
00:00:06 I0803 19:49:42.378010 140526454683456 run_pretraining.py:175]   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768)
00:00:06 I0803 19:49:42.378161 140526454683456 run_pretraining.py:175]   name = bert/embeddings/position_embeddings:0, shape = (512, 768)
00:00:06 I0803 19:49:42.378302 140526454683456 run_pretraining.py:175]   name = bert/embeddings/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 19:49:42.378442 140526454683456 run_pretraining.py:175]   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 19:49:42.378576 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768)
00:00:06 I0803 19:49:42.378742 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.378873 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768)
00:00:06 I0803 19:49:42.379001 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.379127 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768)
00:00:06 I0803 19:49:42.379253 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.379380 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 19:49:42.379507 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.379628 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 19:49:42.379750 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 19:49:42.379872 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072)
00:00:06 I0803 19:49:42.379996 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,)
00:00:06 I0803 19:49:42.380120 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768)
00:00:06 I0803 19:49:42.380245 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.380372 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 19:49:42.380494 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 19:49:42.380617 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768)
00:00:06 I0803 19:49:42.380754 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.380879 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768)
00:00:06 I0803 19:49:42.381005 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.381133 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768)
00:00:06 I0803 19:49:42.381265 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.381389 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 19:49:42.381518 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.381640 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 19:49:42.381761 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 19:49:42.381883 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072)
00:00:06 I0803 19:49:42.382007 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,)
00:00:06 I0803 19:49:42.382130 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768)
00:00:06 I0803 19:49:42.382255 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.382377 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 19:49:42.382498 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 19:49:42.382646 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768)
00:00:06 I0803 19:49:42.382778 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.382904 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768)
00:00:06 I0803 19:49:42.383029 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.383152 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768)
00:00:06 I0803 19:49:42.383285 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.383410 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 19:49:42.383535 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.383656 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 19:49:42.383776 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 19:49:42.383897 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072)
00:00:06 I0803 19:49:42.384030 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,)
00:00:06 I0803 19:49:42.384154 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768)
00:00:06 I0803 19:49:42.384279 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.384401 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 19:49:42.384548 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 19:49:42.384673 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768)
00:00:06 I0803 19:49:42.384799 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.384922 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768)
00:00:06 I0803 19:49:42.385046 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.385171 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768)
00:00:06 I0803 19:49:42.385294 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.385417 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 19:49:42.385541 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.385662 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 19:49:42.385788 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 19:49:42.385910 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072)
00:00:06 I0803 19:49:42.386034 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,)
00:00:06 I0803 19:49:42.386159 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768)
00:00:06 I0803 19:49:42.386284 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.386403 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 19:49:42.386523 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 19:49:42.386672 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768)
00:00:06 I0803 19:49:42.386803 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.386925 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768)
00:00:06 I0803 19:49:42.387056 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.387181 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768)
00:00:06 I0803 19:49:42.387306 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.387430 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 19:49:42.387556 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.387677 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 19:49:42.387798 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 19:49:42.387919 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072)
00:00:06 I0803 19:49:42.388045 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,)
00:00:06 I0803 19:49:42.388169 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768)
00:00:06 I0803 19:49:42.388303 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.388425 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 19:49:42.388546 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 19:49:42.388667 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768)
00:00:06 I0803 19:49:42.388791 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.388912 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768)
00:00:06 I0803 19:49:42.389037 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.389166 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768)
00:00:06 I0803 19:49:42.389292 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.389416 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 19:49:42.389540 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.389662 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 19:49:42.389781 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 19:49:42.389910 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072)
00:00:06 I0803 19:49:42.390043 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,)
00:00:06 I0803 19:49:42.390166 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768)
00:00:06 I0803 19:49:42.390293 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.390413 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 19:49:42.390533 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 19:49:42.390690 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768)
00:00:06 I0803 19:49:42.390820 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.390945 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768)
00:00:06 I0803 19:49:42.391076 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.391201 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768)
00:00:06 I0803 19:49:42.391388 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.391516 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 19:49:42.391641 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.391762 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 19:49:42.391882 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 19:49:42.392004 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072)
00:00:06 I0803 19:49:42.392138 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,)
00:00:06 I0803 19:49:42.392262 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768)
00:00:06 I0803 19:49:42.392388 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.392509 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 19:49:42.392628 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 19:49:42.392749 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768)
00:00:06 I0803 19:49:42.392873 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.393005 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768)
00:00:06 I0803 19:49:42.393129 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.393252 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768)
00:00:06 I0803 19:49:42.393376 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.393499 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 19:49:42.393614 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.393733 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 19:49:42.393854 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 19:49:42.393977 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072)
00:00:06 I0803 19:49:42.394102 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,)
00:00:06 I0803 19:49:42.394225 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768)
00:00:06 I0803 19:49:42.394350 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.394478 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 19:49:42.394599 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 19:49:42.394757 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768)
00:00:06 I0803 19:49:42.394885 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.395007 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768)
00:00:06 I0803 19:49:42.395132 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.395256 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768)
00:00:06 I0803 19:49:42.395383 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.395508 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 19:49:42.395634 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.395755 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 19:49:42.395876 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 19:49:42.396091 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072)
00:00:06 I0803 19:49:42.396225 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,)
00:00:06 I0803 19:49:42.396349 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768)
00:00:06 I0803 19:49:42.396476 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.396605 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 19:49:42.396733 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 19:49:42.396857 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768)
00:00:06 I0803 19:49:42.396982 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.397104 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768)
00:00:06 I0803 19:49:42.397237 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.397363 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768)
00:00:06 I0803 19:49:42.397491 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.397616 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 19:49:42.397740 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.397861 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 19:49:42.397981 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 19:49:42.398102 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072)
00:00:06 I0803 19:49:42.398227 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,)
00:00:06 I0803 19:49:42.398351 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768)
00:00:06 I0803 19:49:42.398474 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.398596 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 19:49:42.398752 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 19:49:42.398875 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768)
00:00:06 I0803 19:49:42.399008 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.399132 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768)
00:00:06 I0803 19:49:42.399258 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.399382 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768)
00:00:06 I0803 19:49:42.399507 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.399629 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 19:49:42.399761 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.399887 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 19:49:42.400011 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 19:49:42.400132 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072)
00:00:06 I0803 19:49:42.400258 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,)
00:00:06 I0803 19:49:42.400383 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768)
00:00:06 I0803 19:49:42.400508 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.400629 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 19:49:42.400749 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 19:49:42.400871 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768)
00:00:06 I0803 19:49:42.400995 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.401119 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768)
00:00:06 I0803 19:49:42.401243 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.401367 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768)
00:00:06 I0803 19:49:42.401490 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.401612 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 19:49:42.401736 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.401861 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 19:49:42.401986 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 19:49:42.402109 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072)
00:00:06 I0803 19:49:42.402235 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,)
00:00:06 I0803 19:49:42.402359 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768)
00:00:06 I0803 19:49:42.402483 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.402604 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 19:49:42.402756 140526454683456 run_pretraining.py:175]   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 19:49:42.402878 140526454683456 run_pretraining.py:175]   name = bert/pooler/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 19:49:42.403004 140526454683456 run_pretraining.py:175]   name = bert/pooler/dense/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.403126 140526454683456 run_pretraining.py:175]   name = cls/predictions/transform/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 19:49:42.403250 140526454683456 run_pretraining.py:175]   name = cls/predictions/transform/dense/bias:0, shape = (768,)
00:00:06 I0803 19:49:42.403377 140526454683456 run_pretraining.py:175]   name = cls/predictions/transform/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 19:49:42.403499 140526454683456 run_pretraining.py:175]   name = cls/predictions/transform/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 19:49:42.403621 140526454683456 run_pretraining.py:175]   name = cls/predictions/output_bias:0, shape = (30522,)
00:00:06 I0803 19:49:42.403751 140526454683456 run_pretraining.py:175]   name = cls/seq_relationship/output_weights:0, shape = (2, 768)
00:00:06 I0803 19:49:42.403877 140526454683456 run_pretraining.py:175]   name = cls/seq_relationship/output_bias:0, shape = (2,)
00:00:06 W0803 19:49:42.412220 140526454683456 deprecation_wrapper.py:119] From /root/w266-final/bert/run_pretraining.py:200: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.
00:00:06 
00:00:06 W0803 19:49:42.434373 140526454683456 deprecation_wrapper.py:119] From /root/w266-final/bert/run_pretraining.py:204: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.
00:00:06 
00:00:06 I0803 19:49:42.497548 140526454683456 estimator.py:1147] Done calling model_fn.
00:00:06 I0803 19:49:42.524405 140526454683456 evaluation.py:255] Starting evaluation at 2019-08-03T19:49:42Z
00:00:06 W0803 19:49:42.754554 140526454683456 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
00:00:06 Instructions for updating:
00:00:06 Use tf.where in 2.0, which has the same broadcast rule as np.where
00:00:07 I0803 19:49:43.238773 140526454683456 monitored_session.py:240] Graph was finalized.
00:00:07 2019-08-03 19:49:43.239214: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
00:00:07 2019-08-03 19:49:43.248949: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000024999 Hz
00:00:07 2019-08-03 19:49:43.249904: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2d00850 executing computations on platform Host. Devices:
00:00:07 2019-08-03 19:49:43.249943: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
00:00:07 W0803 19:49:43.251240 140526454683456 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
00:00:07 Instructions for updating:
00:00:07 Use standard file APIs to check for files with this prefix.
00:00:07 I0803 19:49:43.252729 140526454683456 saver.py:1280] Restoring parameters from /root/w266-final/eval/10-q/ckpt/FinBERT-Combo_128MSL-100K/model.ckpt-100000
00:00:07 2019-08-03 19:49:43.557850: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
00:00:13 I0803 19:49:49.236317 140526454683456 session_manager.py:500] Running local_init_op.
00:00:13 I0803 19:49:49.286493 140526454683456 session_manager.py:502] Done running local_init_op.
00:00:22 I0803 19:49:58.150873 140526454683456 evaluation.py:167] Evaluation [10/100]
00:00:30 I0803 19:50:06.108936 140526454683456 evaluation.py:167] Evaluation [20/100]
00:00:38 I0803 19:50:14.105674 140526454683456 evaluation.py:167] Evaluation [30/100]
00:00:46 I0803 19:50:22.100314 140526454683456 evaluation.py:167] Evaluation [40/100]
00:00:54 I0803 19:50:30.129142 140526454683456 evaluation.py:167] Evaluation [50/100]
00:01:02 I0803 19:50:38.100142 140526454683456 evaluation.py:167] Evaluation [60/100]
00:01:10 I0803 19:50:46.105100 140526454683456 evaluation.py:167] Evaluation [70/100]
00:01:18 I0803 19:50:54.148787 140526454683456 evaluation.py:167] Evaluation [80/100]
00:01:26 I0803 19:51:02.156118 140526454683456 evaluation.py:167] Evaluation [90/100]
00:01:34 I0803 19:51:10.093279 140526454683456 evaluation.py:167] Evaluation [100/100]
00:01:34 I0803 19:51:10.192701 140526454683456 evaluation.py:275] Finished evaluation at 2019-08-03-19:51:10
00:01:34 I0803 19:51:10.193127 140526454683456 estimator.py:2039] Saving dict for global step 100000: global_step = 100000, loss = 1.2795428, masked_lm_accuracy = 0.75010866, masked_lm_loss = 1.1360614, next_sentence_accuracy = 0.95, next_sentence_loss = 0.14388958
00:01:34 I0803 19:51:10.783838 140526454683456 estimator.py:2099] Saving 'checkpoint_path' summary for global step 100000: /root/w266-final/eval/10-q/ckpt/FinBERT-Combo_128MSL-100K/model.ckpt-100000
00:01:34 I0803 19:51:10.784696 140526454683456 error_handling.py:96] evaluation_loop marked as finished
00:01:34 I0803 19:51:10.784974 140526454683456 run_pretraining.py:485] ***** Eval results *****
00:01:34 I0803 19:51:10.785154 140526454683456 run_pretraining.py:487]   global_step = 100000
00:01:34 I0803 19:51:10.785485 140526454683456 run_pretraining.py:487]   loss = 1.2795428
00:01:34 I0803 19:51:10.785667 140526454683456 run_pretraining.py:487]   masked_lm_accuracy = 0.75010866
00:01:34 I0803 19:51:10.785832 140526454683456 run_pretraining.py:487]   masked_lm_loss = 1.1360614
00:01:34 I0803 19:51:10.785995 140526454683456 run_pretraining.py:487]   next_sentence_accuracy = 0.95
00:01:34 I0803 19:51:10.786153 140526454683456 run_pretraining.py:487]   next_sentence_loss = 0.14388958
