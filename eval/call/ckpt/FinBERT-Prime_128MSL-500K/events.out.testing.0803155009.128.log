00:00:03 WARNING: Logging before flag parsing goes to stderr.
00:00:03 W0803 15:50:12.132918 140670287374144 deprecation_wrapper.py:119] From /root/w266-final/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.
00:00:03 
00:00:03 W0803 15:50:12.133272 140670287374144 deprecation_wrapper.py:119] From /root/w266-final/bert/run_pretraining.py:26: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.
00:00:03 
00:00:03 W0803 15:50:12.134222 140670287374144 deprecation_wrapper.py:119] From /root/w266-final/bert/run_pretraining.py:495: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.
00:00:03 
00:00:03 W0803 15:50:12.134854 140670287374144 deprecation_wrapper.py:119] From /root/w266-final/bert/run_pretraining.py:409: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
00:00:03 
00:00:03 W0803 15:50:12.135018 140670287374144 deprecation_wrapper.py:119] From /root/w266-final/bert/run_pretraining.py:409: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
00:00:03 
00:00:03 W0803 15:50:12.135199 140670287374144 deprecation_wrapper.py:119] From /root/w266-final/bert/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.
00:00:03 
00:00:03 W0803 15:50:12.135907 140670287374144 deprecation_wrapper.py:119] From /root/w266-final/bert/run_pretraining.py:416: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.
00:00:03 
00:00:03 W0803 15:50:12.136110 140670287374144 deprecation_wrapper.py:119] From /root/w266-final/bert/run_pretraining.py:420: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.
00:00:03 
00:00:03 W0803 15:50:12.136958 140670287374144 deprecation_wrapper.py:119] From /root/w266-final/bert/run_pretraining.py:422: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
00:00:03 
00:00:03 I0803 15:50:12.137077 140670287374144 run_pretraining.py:422] *** Input Files ***
00:00:03 I0803 15:50:12.137163 140670287374144 run_pretraining.py:424]   /root/w266-final/eval/call/data/call.tfrecord.00-128-20
00:00:03 W0803 15:50:12.678790 140670287374144 lazy_loader.py:50] 
00:00:03 The TensorFlow contrib module will not be included in TensorFlow 2.0.
00:00:03 For more information, please see:
00:00:03   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
00:00:03   * https://github.com/tensorflow/addons
00:00:03   * https://github.com/tensorflow/io (for I/O related ops)
00:00:03 If you depend on functionality not listed there, please file an issue.
00:00:03 
00:00:03 W0803 15:50:12.679443 140670287374144 estimator.py:1984] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7ff025ac9e18>) includes params argument, but params are not passed to Estimator.
00:00:03 I0803 15:50:12.680749 140670287374144 estimator.py:209] Using config: {'_model_dir': '/root/w266-final/eval/call/ckpt/FinBERT-Prime_128MSL-500K', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true
00:00:03 graph_options {
00:00:03   rewrite_options {
00:00:03     meta_optimizer_iterations: ONE
00:00:03   }
00:00:03 }
00:00:03 , '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff0176d9eb8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2), '_cluster': None}
00:00:03 I0803 15:50:12.681425 140670287374144 tpu_context.py:209] _TPUContext: eval_on_tpu True
00:00:03 W0803 15:50:12.681945 140670287374144 tpu_context.py:211] eval_on_tpu ignored because use_tpu is False.
00:00:03 I0803 15:50:12.682077 140670287374144 run_pretraining.py:471] ***** Running evaluation *****
00:00:03 I0803 15:50:12.682184 140670287374144 run_pretraining.py:472]   Batch size = 8
00:00:03 W0803 15:50:12.693057 140670287374144 deprecation_wrapper.py:119] From /root/w266-final/bert/run_pretraining.py:339: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.
00:00:03 
00:00:03 W0803 15:50:12.719141 140670287374144 deprecation.py:323] From /root/w266-final/bert/run_pretraining.py:387: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.
00:00:03 Instructions for updating:
00:00:03 Use `tf.data.experimental.map_and_batch(...)`.
00:00:03 W0803 15:50:12.719310 140670287374144 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/data/python/ops/batching.py:273: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.
00:00:03 Instructions for updating:
00:00:03 Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.
00:00:03 W0803 15:50:12.720986 140670287374144 deprecation_wrapper.py:119] From /root/w266-final/bert/run_pretraining.py:395: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.
00:00:03 
00:00:03 W0803 15:50:12.728095 140670287374144 deprecation.py:323] From /root/w266-final/bert/run_pretraining.py:402: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
00:00:03 Instructions for updating:
00:00:03 Use `tf.cast` instead.
00:00:03 I0803 15:50:12.758112 140670287374144 estimator.py:1145] Calling model_fn.
00:00:03 I0803 15:50:12.758334 140670287374144 tpu_estimator.py:2965] Running eval on CPU
00:00:03 I0803 15:50:12.758803 140670287374144 run_pretraining.py:119] *** Features ***
00:00:03 I0803 15:50:12.758977 140670287374144 run_pretraining.py:121]   name = input_ids, shape = (8, 128)
00:00:03 I0803 15:50:12.759123 140670287374144 run_pretraining.py:121]   name = input_mask, shape = (8, 128)
00:00:03 I0803 15:50:12.759255 140670287374144 run_pretraining.py:121]   name = masked_lm_ids, shape = (8, 20)
00:00:03 I0803 15:50:12.759385 140670287374144 run_pretraining.py:121]   name = masked_lm_positions, shape = (8, 20)
00:00:03 I0803 15:50:12.759511 140670287374144 run_pretraining.py:121]   name = masked_lm_weights, shape = (8, 20)
00:00:03 I0803 15:50:12.759638 140670287374144 run_pretraining.py:121]   name = next_sentence_labels, shape = (8, 1)
00:00:03 I0803 15:50:12.759760 140670287374144 run_pretraining.py:121]   name = segment_ids, shape = (8, 128)
00:00:03 W0803 15:50:12.759998 140670287374144 deprecation_wrapper.py:119] From /root/w266-final/bert/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.
00:00:03 
00:00:03 W0803 15:50:12.762034 140670287374144 deprecation_wrapper.py:119] From /root/w266-final/bert/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.
00:00:03 
00:00:03 W0803 15:50:12.844086 140670287374144 deprecation.py:323] From /root/w266-final/bert/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
00:00:03 Instructions for updating:
00:00:03 Use keras.layers.dense instead.
00:00:06 I0803 15:50:15.882594 140670287374144 run_pretraining.py:169] **** Trainable Variables ****
00:00:06 I0803 15:50:15.882883 140670287374144 run_pretraining.py:175]   name = bert/embeddings/word_embeddings:0, shape = (30522, 768)
00:00:06 I0803 15:50:15.883053 140670287374144 run_pretraining.py:175]   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768)
00:00:06 I0803 15:50:15.883203 140670287374144 run_pretraining.py:175]   name = bert/embeddings/position_embeddings:0, shape = (512, 768)
00:00:06 I0803 15:50:15.883342 140670287374144 run_pretraining.py:175]   name = bert/embeddings/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:50:15.883473 140670287374144 run_pretraining.py:175]   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:50:15.883603 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768)
00:00:06 I0803 15:50:15.883734 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.883864 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768)
00:00:06 I0803 15:50:15.883991 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.884118 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768)
00:00:06 I0803 15:50:15.884248 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.884374 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 15:50:15.884502 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.884623 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:50:15.884744 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:50:15.884868 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072)
00:00:06 I0803 15:50:15.884993 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,)
00:00:06 I0803 15:50:15.885116 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768)
00:00:06 I0803 15:50:15.885242 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.885377 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:50:15.885497 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:50:15.885619 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768)
00:00:06 I0803 15:50:15.885742 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.885865 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768)
00:00:06 I0803 15:50:15.885998 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.886124 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768)
00:00:06 I0803 15:50:15.886248 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.886381 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 15:50:15.886507 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.886657 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:50:15.886784 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:50:15.886906 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072)
00:00:06 I0803 15:50:15.887031 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,)
00:00:06 I0803 15:50:15.887156 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768)
00:00:06 I0803 15:50:15.887282 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.887405 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:50:15.887527 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:50:15.887651 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768)
00:00:06 I0803 15:50:15.887784 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.887911 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768)
00:00:06 I0803 15:50:15.888022 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.888144 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768)
00:00:06 I0803 15:50:15.888268 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.888380 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 15:50:15.888502 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.888621 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:50:15.888741 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:50:15.888861 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072)
00:00:06 I0803 15:50:15.888985 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,)
00:00:06 I0803 15:50:15.889107 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768)
00:00:06 I0803 15:50:15.889239 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.889359 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:50:15.889481 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:50:15.889602 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768)
00:00:06 I0803 15:50:15.889739 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.889863 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768)
00:00:06 I0803 15:50:15.889988 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.890110 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768)
00:00:06 I0803 15:50:15.890235 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.890356 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 15:50:15.890479 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.890599 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:50:15.890750 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:50:15.890873 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072)
00:00:06 I0803 15:50:15.890998 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,)
00:00:06 I0803 15:50:15.891120 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768)
00:00:06 I0803 15:50:15.891243 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.891371 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:50:15.891491 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:50:15.891613 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768)
00:00:06 I0803 15:50:15.891736 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.891857 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768)
00:00:06 I0803 15:50:15.891981 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.892103 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768)
00:00:06 I0803 15:50:15.892232 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.892355 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 15:50:15.892478 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.892599 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:50:15.892717 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:50:15.892839 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072)
00:00:06 I0803 15:50:15.892964 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,)
00:00:06 I0803 15:50:15.893086 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768)
00:00:06 I0803 15:50:15.893211 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.893333 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:50:15.893463 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:50:15.893588 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768)
00:00:06 I0803 15:50:15.893713 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.893836 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768)
00:00:06 I0803 15:50:15.893961 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.894084 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768)
00:00:06 I0803 15:50:15.894216 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.894341 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 15:50:15.894474 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.894596 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:50:15.894746 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:50:15.894868 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072)
00:00:06 I0803 15:50:15.894994 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,)
00:00:06 I0803 15:50:15.895124 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768)
00:00:06 I0803 15:50:15.895248 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.895380 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:50:15.895501 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:50:15.895622 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768)
00:00:06 I0803 15:50:15.895745 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.895866 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768)
00:00:06 I0803 15:50:15.895996 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.896122 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768)
00:00:06 I0803 15:50:15.896310 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.896438 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 15:50:15.896564 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.896693 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:50:15.896816 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:50:15.896938 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072)
00:00:06 I0803 15:50:15.897063 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,)
00:00:06 I0803 15:50:15.897186 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768)
00:00:06 I0803 15:50:15.897318 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.897443 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:50:15.897563 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:50:15.897684 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768)
00:00:06 I0803 15:50:15.897809 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.897932 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768)
00:00:06 I0803 15:50:15.898055 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.898185 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768)
00:00:06 I0803 15:50:15.898310 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.898433 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 15:50:15.898556 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.898705 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:50:15.898828 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:50:15.898949 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072)
00:00:06 I0803 15:50:15.899073 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,)
00:00:06 I0803 15:50:15.899195 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768)
00:00:06 I0803 15:50:15.899318 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.899438 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:50:15.899557 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:50:15.899679 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768)
00:00:06 I0803 15:50:15.899803 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.899926 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768)
00:00:06 I0803 15:50:15.900050 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.900172 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768)
00:00:06 I0803 15:50:15.900296 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.900418 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 15:50:15.900542 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.900662 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:50:15.900781 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:50:15.900904 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072)
00:00:06 I0803 15:50:15.901071 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,)
00:00:06 I0803 15:50:15.901216 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768)
00:00:06 I0803 15:50:15.901343 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.901467 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:50:15.901588 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:50:15.901711 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768)
00:00:06 I0803 15:50:15.901835 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.901957 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768)
00:00:06 I0803 15:50:15.902088 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.902215 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768)
00:00:06 I0803 15:50:15.902340 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.902465 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 15:50:15.902590 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.902745 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:50:15.902866 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:50:15.902989 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072)
00:00:06 I0803 15:50:15.903116 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,)
00:00:06 I0803 15:50:15.903241 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768)
00:00:06 I0803 15:50:15.903364 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.903484 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:50:15.903603 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:50:15.903723 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768)
00:00:06 I0803 15:50:15.903845 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.903967 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768)
00:00:06 I0803 15:50:15.904097 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.904220 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768)
00:00:06 I0803 15:50:15.904343 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.904466 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 15:50:15.904591 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.904710 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:50:15.904829 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:50:15.904958 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072)
00:00:06 I0803 15:50:15.905083 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,)
00:00:06 I0803 15:50:15.905206 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768)
00:00:06 I0803 15:50:15.905340 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.905463 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:50:15.905583 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:50:15.905704 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768)
00:00:06 I0803 15:50:15.905827 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.905948 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768)
00:00:06 I0803 15:50:15.906069 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.906192 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768)
00:00:06 I0803 15:50:15.906314 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.906436 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 15:50:15.906558 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.906708 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:50:15.906831 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:50:15.906953 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072)
00:00:06 I0803 15:50:15.907083 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,)
00:00:06 I0803 15:50:15.907205 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768)
00:00:06 I0803 15:50:15.907333 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.907454 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:50:15.907573 140670287374144 run_pretraining.py:175]   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:50:15.907700 140670287374144 run_pretraining.py:175]   name = bert/pooler/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 15:50:15.907824 140670287374144 run_pretraining.py:175]   name = bert/pooler/dense/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.907945 140670287374144 run_pretraining.py:175]   name = cls/predictions/transform/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 15:50:15.908067 140670287374144 run_pretraining.py:175]   name = cls/predictions/transform/dense/bias:0, shape = (768,)
00:00:06 I0803 15:50:15.908192 140670287374144 run_pretraining.py:175]   name = cls/predictions/transform/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:50:15.908313 140670287374144 run_pretraining.py:175]   name = cls/predictions/transform/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:50:15.908431 140670287374144 run_pretraining.py:175]   name = cls/predictions/output_bias:0, shape = (30522,)
00:00:06 I0803 15:50:15.908550 140670287374144 run_pretraining.py:175]   name = cls/seq_relationship/output_weights:0, shape = (2, 768)
00:00:06 I0803 15:50:15.908674 140670287374144 run_pretraining.py:175]   name = cls/seq_relationship/output_bias:0, shape = (2,)
00:00:06 W0803 15:50:15.916882 140670287374144 deprecation_wrapper.py:119] From /root/w266-final/bert/run_pretraining.py:200: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.
00:00:06 
00:00:06 W0803 15:50:15.938641 140670287374144 deprecation_wrapper.py:119] From /root/w266-final/bert/run_pretraining.py:204: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.
00:00:06 
00:00:06 I0803 15:50:16.000832 140670287374144 estimator.py:1147] Done calling model_fn.
00:00:07 I0803 15:50:16.027399 140670287374144 evaluation.py:255] Starting evaluation at 2019-08-03T15:50:16Z
00:00:07 W0803 15:50:16.254468 140670287374144 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
00:00:07 Instructions for updating:
00:00:07 Use tf.where in 2.0, which has the same broadcast rule as np.where
00:00:07 I0803 15:50:16.730744 140670287374144 monitored_session.py:240] Graph was finalized.
00:00:07 2019-08-03 15:50:16.731183: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
00:00:07 2019-08-03 15:50:16.740927: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000024999 Hz
00:00:07 2019-08-03 15:50:16.741614: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4986650 executing computations on platform Host. Devices:
00:00:07 2019-08-03 15:50:16.741645: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
00:00:07 W0803 15:50:16.742750 140670287374144 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
00:00:07 Instructions for updating:
00:00:07 Use standard file APIs to check for files with this prefix.
00:00:07 I0803 15:50:16.746582 140670287374144 saver.py:1280] Restoring parameters from /root/w266-final/eval/call/ckpt/FinBERT-Prime_128MSL-500K/model.ckpt-500000
00:00:08 2019-08-03 15:50:17.041745: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
00:00:08 I0803 15:50:17.617798 140670287374144 session_manager.py:500] Running local_init_op.
00:00:08 I0803 15:50:17.665846 140670287374144 session_manager.py:502] Done running local_init_op.
00:00:17 I0803 15:50:26.742991 140670287374144 evaluation.py:167] Evaluation [10/100]
00:00:25 I0803 15:50:34.907216 140670287374144 evaluation.py:167] Evaluation [20/100]
00:00:34 I0803 15:50:43.091608 140670287374144 evaluation.py:167] Evaluation [30/100]
00:00:42 I0803 15:50:51.281682 140670287374144 evaluation.py:167] Evaluation [40/100]
00:00:50 I0803 15:50:59.457586 140670287374144 evaluation.py:167] Evaluation [50/100]
00:00:58 I0803 15:51:07.672268 140670287374144 evaluation.py:167] Evaluation [60/100]
00:01:06 I0803 15:51:15.861043 140670287374144 evaluation.py:167] Evaluation [70/100]
00:01:15 I0803 15:51:24.053154 140670287374144 evaluation.py:167] Evaluation [80/100]
00:01:23 I0803 15:51:32.268540 140670287374144 evaluation.py:167] Evaluation [90/100]
00:01:31 I0803 15:51:40.420536 140670287374144 evaluation.py:167] Evaluation [100/100]
00:01:31 I0803 15:51:40.516317 140670287374144 evaluation.py:275] Finished evaluation at 2019-08-03-15:51:40
00:01:31 I0803 15:51:40.516725 140670287374144 estimator.py:2039] Saving dict for global step 500000: global_step = 500000, loss = 5.92793, masked_lm_accuracy = 0.42809233, masked_lm_loss = 3.6206315, next_sentence_accuracy = 0.53125, next_sentence_loss = 2.279772
00:01:32 I0803 15:51:41.099146 140670287374144 estimator.py:2099] Saving 'checkpoint_path' summary for global step 500000: /root/w266-final/eval/call/ckpt/FinBERT-Prime_128MSL-500K/model.ckpt-500000
00:01:32 I0803 15:51:41.099963 140670287374144 error_handling.py:96] evaluation_loop marked as finished
00:01:32 I0803 15:51:41.100231 140670287374144 run_pretraining.py:485] ***** Eval results *****
00:01:32 I0803 15:51:41.100405 140670287374144 run_pretraining.py:487]   global_step = 500000
00:01:32 I0803 15:51:41.100674 140670287374144 run_pretraining.py:487]   loss = 5.92793
00:01:32 I0803 15:51:41.100848 140670287374144 run_pretraining.py:487]   masked_lm_accuracy = 0.42809233
00:01:32 I0803 15:51:41.101007 140670287374144 run_pretraining.py:487]   masked_lm_loss = 3.6206315
00:01:32 I0803 15:51:41.101159 140670287374144 run_pretraining.py:487]   next_sentence_accuracy = 0.53125
00:01:32 I0803 15:51:41.101311 140670287374144 run_pretraining.py:487]   next_sentence_loss = 2.279772
