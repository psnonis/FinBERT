00:00:02 WARNING: Logging before flag parsing goes to stderr.
00:00:02 W0803 15:56:19.354821 140532331562816 deprecation_wrapper.py:119] From /root/w266-final/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.
00:00:02 
00:00:02 W0803 15:56:19.355170 140532331562816 deprecation_wrapper.py:119] From /root/w266-final/bert/run_pretraining.py:26: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.
00:00:02 
00:00:02 W0803 15:56:19.356119 140532331562816 deprecation_wrapper.py:119] From /root/w266-final/bert/run_pretraining.py:495: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.
00:00:02 
00:00:02 W0803 15:56:19.356727 140532331562816 deprecation_wrapper.py:119] From /root/w266-final/bert/run_pretraining.py:409: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
00:00:02 
00:00:02 W0803 15:56:19.356888 140532331562816 deprecation_wrapper.py:119] From /root/w266-final/bert/run_pretraining.py:409: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
00:00:02 
00:00:02 W0803 15:56:19.357066 140532331562816 deprecation_wrapper.py:119] From /root/w266-final/bert/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.
00:00:02 
00:00:02 W0803 15:56:19.357775 140532331562816 deprecation_wrapper.py:119] From /root/w266-final/bert/run_pretraining.py:416: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.
00:00:02 
00:00:02 W0803 15:56:19.357978 140532331562816 deprecation_wrapper.py:119] From /root/w266-final/bert/run_pretraining.py:420: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.
00:00:02 
00:00:02 W0803 15:56:19.358856 140532331562816 deprecation_wrapper.py:119] From /root/w266-final/bert/run_pretraining.py:422: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
00:00:02 
00:00:02 I0803 15:56:19.358974 140532331562816 run_pretraining.py:422] *** Input Files ***
00:00:02 I0803 15:56:19.359071 140532331562816 run_pretraining.py:424]   /root/w266-final/eval/call/data/call.tfrecord.00-128-20
00:00:02 W0803 15:56:19.896301 140532331562816 lazy_loader.py:50] 
00:00:02 The TensorFlow contrib module will not be included in TensorFlow 2.0.
00:00:02 For more information, please see:
00:00:02   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
00:00:02   * https://github.com/tensorflow/addons
00:00:02   * https://github.com/tensorflow/io (for I/O related ops)
00:00:02 If you depend on functionality not listed there, please file an issue.
00:00:02 
00:00:02 W0803 15:56:19.896934 140532331562816 estimator.py:1984] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fd006ddfe18>) includes params argument, but params are not passed to Estimator.
00:00:02 I0803 15:56:19.898148 140532331562816 estimator.py:209] Using config: {'_model_dir': '/root/w266-final/eval/call/ckpt/FinBERT-Combo_128MSL-500K', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true
00:00:02 graph_options {
00:00:02   rewrite_options {
00:00:02     meta_optimizer_iterations: ONE
00:00:02   }
00:00:02 }
00:00:02 , '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd004a1bf28>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2), '_cluster': None}
00:00:02 I0803 15:56:19.898880 140532331562816 tpu_context.py:209] _TPUContext: eval_on_tpu True
00:00:02 W0803 15:56:19.899407 140532331562816 tpu_context.py:211] eval_on_tpu ignored because use_tpu is False.
00:00:02 I0803 15:56:19.899536 140532331562816 run_pretraining.py:471] ***** Running evaluation *****
00:00:02 I0803 15:56:19.899643 140532331562816 run_pretraining.py:472]   Batch size = 8
00:00:02 W0803 15:56:19.910530 140532331562816 deprecation_wrapper.py:119] From /root/w266-final/bert/run_pretraining.py:339: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.
00:00:02 
00:00:02 W0803 15:56:19.936496 140532331562816 deprecation.py:323] From /root/w266-final/bert/run_pretraining.py:387: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.
00:00:02 Instructions for updating:
00:00:02 Use `tf.data.experimental.map_and_batch(...)`.
00:00:02 W0803 15:56:19.936661 140532331562816 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/data/python/ops/batching.py:273: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.
00:00:02 Instructions for updating:
00:00:02 Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.
00:00:02 W0803 15:56:19.938345 140532331562816 deprecation_wrapper.py:119] From /root/w266-final/bert/run_pretraining.py:395: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.
00:00:02 
00:00:02 W0803 15:56:19.945443 140532331562816 deprecation.py:323] From /root/w266-final/bert/run_pretraining.py:402: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
00:00:02 Instructions for updating:
00:00:02 Use `tf.cast` instead.
00:00:02 I0803 15:56:19.975934 140532331562816 estimator.py:1145] Calling model_fn.
00:00:02 I0803 15:56:19.976171 140532331562816 tpu_estimator.py:2965] Running eval on CPU
00:00:02 I0803 15:56:19.976624 140532331562816 run_pretraining.py:119] *** Features ***
00:00:02 I0803 15:56:19.976800 140532331562816 run_pretraining.py:121]   name = input_ids, shape = (8, 128)
00:00:02 I0803 15:56:19.976945 140532331562816 run_pretraining.py:121]   name = input_mask, shape = (8, 128)
00:00:02 I0803 15:56:19.977081 140532331562816 run_pretraining.py:121]   name = masked_lm_ids, shape = (8, 20)
00:00:02 I0803 15:56:19.977210 140532331562816 run_pretraining.py:121]   name = masked_lm_positions, shape = (8, 20)
00:00:02 I0803 15:56:19.977339 140532331562816 run_pretraining.py:121]   name = masked_lm_weights, shape = (8, 20)
00:00:02 I0803 15:56:19.977464 140532331562816 run_pretraining.py:121]   name = next_sentence_labels, shape = (8, 1)
00:00:02 I0803 15:56:19.977587 140532331562816 run_pretraining.py:121]   name = segment_ids, shape = (8, 128)
00:00:02 W0803 15:56:19.977830 140532331562816 deprecation_wrapper.py:119] From /root/w266-final/bert/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.
00:00:02 
00:00:02 W0803 15:56:19.979927 140532331562816 deprecation_wrapper.py:119] From /root/w266-final/bert/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.
00:00:02 
00:00:03 W0803 15:56:20.062978 140532331562816 deprecation.py:323] From /root/w266-final/bert/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
00:00:03 Instructions for updating:
00:00:03 Use keras.layers.dense instead.
00:00:06 I0803 15:56:23.134423 140532331562816 run_pretraining.py:169] **** Trainable Variables ****
00:00:06 I0803 15:56:23.134701 140532331562816 run_pretraining.py:175]   name = bert/embeddings/word_embeddings:0, shape = (30522, 768)
00:00:06 I0803 15:56:23.134864 140532331562816 run_pretraining.py:175]   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768)
00:00:06 I0803 15:56:23.135014 140532331562816 run_pretraining.py:175]   name = bert/embeddings/position_embeddings:0, shape = (512, 768)
00:00:06 I0803 15:56:23.135142 140532331562816 run_pretraining.py:175]   name = bert/embeddings/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:56:23.135275 140532331562816 run_pretraining.py:175]   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:56:23.135407 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768)
00:00:06 I0803 15:56:23.135540 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.135667 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768)
00:00:06 I0803 15:56:23.135796 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.135920 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768)
00:00:06 I0803 15:56:23.136046 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.136170 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 15:56:23.136296 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.136419 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:56:23.136540 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:56:23.136661 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072)
00:00:06 I0803 15:56:23.136796 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,)
00:00:06 I0803 15:56:23.136920 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768)
00:00:06 I0803 15:56:23.137046 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.137167 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:56:23.137289 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:56:23.137411 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768)
00:00:06 I0803 15:56:23.137536 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.137667 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768)
00:00:06 I0803 15:56:23.137794 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.137918 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768)
00:00:06 I0803 15:56:23.138046 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.138180 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 15:56:23.138308 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.138431 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:56:23.138552 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:56:23.138704 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072)
00:00:06 I0803 15:56:23.138834 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,)
00:00:06 I0803 15:56:23.138958 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768)
00:00:06 I0803 15:56:23.139083 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.139206 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:56:23.139327 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:56:23.139452 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768)
00:00:06 I0803 15:56:23.139576 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.139698 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768)
00:00:06 I0803 15:56:23.139821 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.139944 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768)
00:00:06 I0803 15:56:23.140075 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.140201 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 15:56:23.140326 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.140446 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:56:23.140565 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:56:23.140686 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072)
00:00:06 I0803 15:56:23.140810 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,)
00:00:06 I0803 15:56:23.140933 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768)
00:00:06 I0803 15:56:23.141066 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.141185 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:56:23.141306 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:56:23.141428 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768)
00:00:06 I0803 15:56:23.141561 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.141684 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768)
00:00:06 I0803 15:56:23.141808 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.141931 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768)
00:00:06 I0803 15:56:23.142054 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.142176 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 15:56:23.142300 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.142420 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:56:23.142543 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:56:23.142693 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072)
00:00:06 I0803 15:56:23.142821 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,)
00:00:06 I0803 15:56:23.142944 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768)
00:00:06 I0803 15:56:23.143068 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.143187 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:56:23.143307 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:56:23.143429 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768)
00:00:06 I0803 15:56:23.143559 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.143683 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768)
00:00:06 I0803 15:56:23.143808 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.143931 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768)
00:00:06 I0803 15:56:23.144061 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.144184 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 15:56:23.144309 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.144428 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:56:23.144546 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:56:23.144668 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072)
00:00:06 I0803 15:56:23.144791 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,)
00:00:06 I0803 15:56:23.144914 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768)
00:00:06 I0803 15:56:23.145038 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.145159 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:56:23.145291 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:56:23.145416 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768)
00:00:06 I0803 15:56:23.145542 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.145665 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768)
00:00:06 I0803 15:56:23.145791 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.145914 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768)
00:00:06 I0803 15:56:23.146044 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.146169 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 15:56:23.146294 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.146414 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:56:23.146534 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:56:23.146688 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072)
00:00:06 I0803 15:56:23.146829 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,)
00:00:06 I0803 15:56:23.146960 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768)
00:00:06 I0803 15:56:23.147087 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.147208 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:56:23.147330 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:56:23.147453 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768)
00:00:06 I0803 15:56:23.147576 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.147698 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768)
00:00:06 I0803 15:56:23.147820 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.147950 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768)
00:00:06 I0803 15:56:23.148139 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.148268 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 15:56:23.148395 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.148515 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:56:23.148637 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:56:23.148759 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072)
00:00:06 I0803 15:56:23.148882 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,)
00:00:06 I0803 15:56:23.149006 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768)
00:00:06 I0803 15:56:23.149139 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.149262 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:56:23.149382 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:56:23.149504 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768)
00:00:06 I0803 15:56:23.149629 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.149751 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768)
00:00:06 I0803 15:56:23.149873 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.150005 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768)
00:00:06 I0803 15:56:23.150129 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.150250 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 15:56:23.150375 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.150495 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:56:23.150603 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:56:23.150745 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072)
00:00:06 I0803 15:56:23.150870 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,)
00:00:06 I0803 15:56:23.150994 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768)
00:00:06 I0803 15:56:23.151118 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.151237 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:56:23.151356 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:56:23.151478 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768)
00:00:06 I0803 15:56:23.151602 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.151723 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768)
00:00:06 I0803 15:56:23.151847 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.151969 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768)
00:00:06 I0803 15:56:23.152092 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.152214 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 15:56:23.152338 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.152459 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:56:23.152577 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:56:23.152698 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072)
00:00:06 I0803 15:56:23.152895 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,)
00:00:06 I0803 15:56:23.153036 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768)
00:00:06 I0803 15:56:23.153163 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.153289 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:56:23.153415 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:56:23.153540 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768)
00:00:06 I0803 15:56:23.153665 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.153787 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768)
00:00:06 I0803 15:56:23.153911 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.154039 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768)
00:00:06 I0803 15:56:23.154164 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.154288 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 15:56:23.154413 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.154532 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:56:23.154675 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:56:23.154800 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072)
00:00:06 I0803 15:56:23.154925 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,)
00:00:06 I0803 15:56:23.155047 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768)
00:00:06 I0803 15:56:23.155171 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.155291 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:56:23.155409 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:56:23.155529 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768)
00:00:06 I0803 15:56:23.155651 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.155772 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768)
00:00:06 I0803 15:56:23.155901 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.156023 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768)
00:00:06 I0803 15:56:23.156146 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.156266 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 15:56:23.156390 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.156508 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:56:23.156627 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:56:23.156763 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072)
00:00:06 I0803 15:56:23.156890 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,)
00:00:06 I0803 15:56:23.157012 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768)
00:00:06 I0803 15:56:23.157135 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.157255 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:56:23.157372 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:56:23.157493 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768)
00:00:06 I0803 15:56:23.157614 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.157734 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768)
00:00:06 I0803 15:56:23.157857 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.157978 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768)
00:00:06 I0803 15:56:23.158100 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.158219 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 15:56:23.158341 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.158459 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:56:23.158585 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:56:23.158734 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072)
00:00:06 I0803 15:56:23.158865 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,)
00:00:06 I0803 15:56:23.158987 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768)
00:00:06 I0803 15:56:23.159109 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.159227 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:56:23.159344 140532331562816 run_pretraining.py:175]   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:56:23.159463 140532331562816 run_pretraining.py:175]   name = bert/pooler/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 15:56:23.159585 140532331562816 run_pretraining.py:175]   name = bert/pooler/dense/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.159707 140532331562816 run_pretraining.py:175]   name = cls/predictions/transform/dense/kernel:0, shape = (768, 768)
00:00:06 I0803 15:56:23.159828 140532331562816 run_pretraining.py:175]   name = cls/predictions/transform/dense/bias:0, shape = (768,)
00:00:06 I0803 15:56:23.159954 140532331562816 run_pretraining.py:175]   name = cls/predictions/transform/LayerNorm/beta:0, shape = (768,)
00:00:06 I0803 15:56:23.160073 140532331562816 run_pretraining.py:175]   name = cls/predictions/transform/LayerNorm/gamma:0, shape = (768,)
00:00:06 I0803 15:56:23.160189 140532331562816 run_pretraining.py:175]   name = cls/predictions/output_bias:0, shape = (30522,)
00:00:06 I0803 15:56:23.160308 140532331562816 run_pretraining.py:175]   name = cls/seq_relationship/output_weights:0, shape = (2, 768)
00:00:06 I0803 15:56:23.160435 140532331562816 run_pretraining.py:175]   name = cls/seq_relationship/output_bias:0, shape = (2,)
00:00:06 W0803 15:56:23.168755 140532331562816 deprecation_wrapper.py:119] From /root/w266-final/bert/run_pretraining.py:200: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.
00:00:06 
00:00:06 W0803 15:56:23.190805 140532331562816 deprecation_wrapper.py:119] From /root/w266-final/bert/run_pretraining.py:204: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.
00:00:06 
00:00:06 I0803 15:56:23.253837 140532331562816 estimator.py:1147] Done calling model_fn.
00:00:06 I0803 15:56:23.280738 140532331562816 evaluation.py:255] Starting evaluation at 2019-08-03T15:56:23Z
00:00:06 W0803 15:56:23.510536 140532331562816 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
00:00:06 Instructions for updating:
00:00:06 Use tf.where in 2.0, which has the same broadcast rule as np.where
00:00:06 I0803 15:56:23.992422 140532331562816 monitored_session.py:240] Graph was finalized.
00:00:06 2019-08-03 15:56:23.992846: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
00:00:06 2019-08-03 15:56:24.002432: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000024999 Hz
00:00:06 2019-08-03 15:56:24.003239: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x58a5a90 executing computations on platform Host. Devices:
00:00:06 2019-08-03 15:56:24.003277: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
00:00:06 W0803 15:56:24.004472 140532331562816 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
00:00:06 Instructions for updating:
00:00:06 Use standard file APIs to check for files with this prefix.
00:00:06 I0803 15:56:24.006065 140532331562816 saver.py:1280] Restoring parameters from /root/w266-final/eval/call/ckpt/FinBERT-Combo_128MSL-500K/model.ckpt-500000
00:00:07 2019-08-03 15:56:24.302339: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
00:00:07 I0803 15:56:24.877879 140532331562816 session_manager.py:500] Running local_init_op.
00:00:07 I0803 15:56:24.927554 140532331562816 session_manager.py:502] Done running local_init_op.
00:00:16 I0803 15:56:33.949891 140532331562816 evaluation.py:167] Evaluation [10/100]
00:00:25 I0803 15:56:42.135665 140532331562816 evaluation.py:167] Evaluation [20/100]
00:00:33 I0803 15:56:50.273355 140532331562816 evaluation.py:167] Evaluation [30/100]
00:00:41 I0803 15:56:58.418814 140532331562816 evaluation.py:167] Evaluation [40/100]
00:00:49 I0803 15:57:06.585055 140532331562816 evaluation.py:167] Evaluation [50/100]
00:00:57 I0803 15:57:14.737329 140532331562816 evaluation.py:167] Evaluation [60/100]
00:01:05 I0803 15:57:22.861314 140532331562816 evaluation.py:167] Evaluation [70/100]
00:01:13 I0803 15:57:30.988030 140532331562816 evaluation.py:167] Evaluation [80/100]
00:01:22 I0803 15:57:39.198861 140532331562816 evaluation.py:167] Evaluation [90/100]
00:01:30 I0803 15:57:47.402183 140532331562816 evaluation.py:167] Evaluation [100/100]
00:01:30 I0803 15:57:47.499132 140532331562816 evaluation.py:275] Finished evaluation at 2019-08-03-15:57:47
00:01:30 I0803 15:57:47.499531 140532331562816 estimator.py:2039] Saving dict for global step 500000: global_step = 500000, loss = 8.683033, masked_lm_accuracy = 0.42838824, masked_lm_loss = 3.7807398, next_sentence_accuracy = 0.52, next_sentence_loss = 4.8727236
00:01:31 I0803 15:57:48.064015 140532331562816 estimator.py:2099] Saving 'checkpoint_path' summary for global step 500000: /root/w266-final/eval/call/ckpt/FinBERT-Combo_128MSL-500K/model.ckpt-500000
00:01:31 I0803 15:57:48.064819 140532331562816 error_handling.py:96] evaluation_loop marked as finished
00:01:31 I0803 15:57:48.065087 140532331562816 run_pretraining.py:485] ***** Eval results *****
00:01:31 I0803 15:57:48.065257 140532331562816 run_pretraining.py:487]   global_step = 500000
00:01:31 I0803 15:57:48.065570 140532331562816 run_pretraining.py:487]   loss = 8.683033
00:01:31 I0803 15:57:48.065744 140532331562816 run_pretraining.py:487]   masked_lm_accuracy = 0.42838824
00:01:31 I0803 15:57:48.065900 140532331562816 run_pretraining.py:487]   masked_lm_loss = 3.7807398
00:01:31 I0803 15:57:48.066050 140532331562816 run_pretraining.py:487]   next_sentence_accuracy = 0.52
00:01:31 I0803 15:57:48.066196 140532331562816 run_pretraining.py:487]   next_sentence_loss = 4.8727236
